{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb234518-f717-49fc-9976-a9b6f112b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import numpy as np\n",
    "import openml\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import kaleido\n",
    "import plotly\n",
    "import scipy.stats as stats\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from optuna.samplers import TPESampler, CmaEsSampler\n",
    "from xgboost import XGBClassifier\n",
    "from plotly.io import show\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb9d9afd-4fd2-4e41-ac94-0cc3e395f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids = [\n",
    "    1590,   # Adult\n",
    "    1510,   # Breast Cancer Wisconsin (Diagnostic)\n",
    "    1461,   # Bank Marketing\n",
    "    24,     # Mushroom\n",
    "    40945   # Titanic\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e0f75f7-282c-4903-8277-b733ba8abe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_prepare(openml_id):\n",
    "    global y\n",
    "    global X\n",
    "    dataset = openml.datasets.get_dataset(openml_id)\n",
    "    print(f\">>> {dataset.name} (ID: {openml_id})\")\n",
    "    X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format='dataframe')\n",
    "    for col in X.select_dtypes(include=['category', 'object']):\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    #scaler = MinMaxScaler()\n",
    "    #X_imputed = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X.columns)\n",
    "    if y.dtype == 'category':\n",
    "        y = LabelEncoder().fit_transform(y)\n",
    "    zbior = X_imputed['Target'] = y\n",
    "    return X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bf5e5d6-fbfb-4b6f-9eb6-7bc41a831725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> adult (ID: 1590)\n"
     ]
    }
   ],
   "source": [
    "zbior = fetch_and_prepare(1590)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69ea0ae3-8844-4f83-8d82-14f7a5c8737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(zbior.iloc[:, :-1], zbior['Target'], test_size=0.30, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "             \n",
    "    booster = trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"])\n",
    "    if booster == \"gblinear\":\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 921, 4551)\n",
    "        eta = trial.suggest_float(\"eta\", 0.002, 0.355, log=True)\n",
    "        lambda_ = trial.suggest_float(\"lambda\", 0.008, 29.755, log=True)     \n",
    "        alpha = trial.suggest_float(\"alpha\", 0.002, 6.105, log=True)\n",
    "    else:\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 921, 4551)          \n",
    "        eta = trial.suggest_float(\"eta\", 0.002, 0.355, log=True)             \n",
    "        subsample = trial.suggest_float(\"subsample\", 0.545, 0.958)  \n",
    "        max_depth = trial.suggest_int(\"max_depth\", 6, 14)\n",
    "        min_child_weight = trial.suggest_float(\"min_child_weight\", 1.295, 6.984)\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.419, 0.864)  \n",
    "        colsample_bylevel = trial.suggest_float(\"colsample_bylevel\", 0.335, 0.886)\n",
    "        lambda_ = trial.suggest_float(\"lambda\", 0.008, 29.755, log=True)     \n",
    "        alpha = trial.suggest_float(\"alpha\", 0.002, 6.105, log=True)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    wyniki = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        X_train_fold = X_train_fold.reset_index(drop=True)\n",
    "        X_test_fold = X_test_fold.reset_index(drop=True)\n",
    "        y_train_fold = y_train_fold.reset_index(drop=True)\n",
    "        y_test_fold = y_test_fold.reset_index(drop=True)\n",
    "\n",
    "        X_train_fold = list(zip(*[X_train_fold[col] for col in X_train_fold]))\n",
    "        X_test_fold = list(zip(*[X_test_fold[col] for col in X_test_fold]))\n",
    "\n",
    "        XGBoost = XGBClassifier(n_estimators=n_estimators,\n",
    "        eta=eta, subsample=subsample, booster=booster, max_depth=max_depth, min_child_weight=min_child_weight, colsample_bytree=colsample_bytree,\n",
    "        colsample_bylevel=colsample_bylevel,\n",
    "        reg_lambda=lambda_, reg_alpha=alpha, random_state=42, n_jobs=-1, eval_metric=\"auc\")\n",
    "\n",
    "\n",
    "        model = XGBoost.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "\n",
    "        y_pred_proba = model.predict_proba(X_test_fold)[:, 1]\n",
    "        auc = roc_auc_score(y_test_fold, y_pred_proba)\n",
    "                                            \n",
    "        wyniki.append(auc)\n",
    "\n",
    "    rezultat = np.mean(wyniki)\n",
    "    return rezultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dfa1a24-71d9-41e4-806e-d44c68b0da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 20:52:05,660] A new study created in memory with name: no-name-0fb22780-5ff6-415c-a8a0-3b37773a4b8d\n",
      "[W 2025-11-12 22:25:42,477] Trial 0 failed with parameters: {'booster': 'dart', 'n_estimators': 1710, 'eta': 0.3450834885243372, 'subsample': 0.6574620703642793, 'max_depth': 13, 'min_child_weight': 4.049507099046526, 'colsample_bytree': 0.5840683867598503, 'colsample_bylevel': 0.5422733421113989, 'lambda': 7.53408469940207, 'alpha': 0.007367552757549518} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mikolaj Ozimek\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Mikolaj Ozimek\\AppData\\Local\\Temp\\ipykernel_12892\\1143840741.py\", line 43, in objective\n",
      "    model = XGBoost.fit(X_train_fold, y_train_fold)\n",
      "  File \"C:\\Users\\Mikolaj Ozimek\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Mikolaj Ozimek\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1803, in fit\n",
      "    self._Booster = train(\n",
      "                    ~~~~~^\n",
      "        params,\n",
      "        ^^^^^^^\n",
      "    ...<9 lines>...\n",
      "        callbacks=self.callbacks,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\Mikolaj Ozimek\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Mikolaj Ozimek\\anaconda3\\Lib\\site-packages\\xgboost\\training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mikolaj Ozimek\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 2434, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self.handle, ctypes.c_int(iteration), dtrain.handle\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "KeyboardInterrupt\n",
      "[W 2025-11-12 22:25:42,483] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m,sampler\u001b[38;5;241m=\u001b[39mTPESampler())\n\u001b[1;32m----> 2\u001b[0m wynik \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m     _optimize(\n\u001b[0;32m    491\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    492\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    493\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    494\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    495\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    496\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    497\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    498\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    499\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    500\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[0;32m     64\u001b[0m             study,\n\u001b[0;32m     65\u001b[0m             func,\n\u001b[0;32m     66\u001b[0m             n_trials,\n\u001b[0;32m     67\u001b[0m             timeout,\n\u001b[0;32m     68\u001b[0m             catch,\n\u001b[0;32m     69\u001b[0m             callbacks,\n\u001b[0;32m     70\u001b[0m             gc_after_trial,\n\u001b[0;32m     71\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     73\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    257\u001b[0m ):\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[16], line 43\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     35\u001b[0m X_test_fold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[X_test_fold[col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m X_test_fold]))\n\u001b[0;32m     37\u001b[0m XGBoost \u001b[38;5;241m=\u001b[39m XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39mn_estimators,\n\u001b[0;32m     38\u001b[0m eta\u001b[38;5;241m=\u001b[39meta, subsample\u001b[38;5;241m=\u001b[39msubsample, booster\u001b[38;5;241m=\u001b[39mbooster, max_depth\u001b[38;5;241m=\u001b[39mmax_depth, min_child_weight\u001b[38;5;241m=\u001b[39mmin_child_weight, colsample_bytree\u001b[38;5;241m=\u001b[39mcolsample_bytree,\n\u001b[0;32m     39\u001b[0m colsample_bylevel\u001b[38;5;241m=\u001b[39mcolsample_bylevel,\n\u001b[0;32m     40\u001b[0m reg_lambda\u001b[38;5;241m=\u001b[39mlambda_, reg_alpha\u001b[38;5;241m=\u001b[39malpha, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBoost\u001b[38;5;241m.\u001b[39mfit(X_train_fold, y_train_fold)\n\u001b[0;32m     46\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_fold)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     47\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test_fold, y_pred_proba)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:774\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    773\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1803\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1783\u001b[0m evals_result: EvalsLog \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1784\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1785\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1786\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1800\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[0;32m   1801\u001b[0m )\n\u001b[1;32m-> 1803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1804\u001b[0m     params,\n\u001b[0;32m   1805\u001b[0m     train_dmatrix,\n\u001b[0;32m   1806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1807\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1808\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1809\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1810\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1811\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1812\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1813\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1814\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   1815\u001b[0m )\n\u001b[0;32m   1817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1818\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:774\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    773\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2434\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2433\u001b[0m     _check_call(\n\u001b[1;32m-> 2434\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2435\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2436\u001b[0m         )\n\u001b[0;32m   2437\u001b[0m     )\n\u001b[0;32m   2438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2439\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize',sampler=TPESampler())\n",
    "wynik = study.optimize(objective, n_trials=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b1f9b82-6489-4b22-a7d7-2d45883e3e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8706308982450709"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc7a5fca-101c-45c3-8767-46466cc603f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'learning_rate': 0.005774611041567384,\n",
       " 'n_estimators': 1710,\n",
       " 'subsample': 0.9762184215070683,\n",
       " 'colsample_bytree': 0.7290221048349554,\n",
       " 'min_child_weight': 6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
