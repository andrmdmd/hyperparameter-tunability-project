{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1460a26f-d342-4d59-9adb-5c1c41b0c59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import numpy as np\n",
    "import openml\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from optuna.samplers import TPESampler, CmaEsSampler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627349b-df3d-42a9-b647-6e6db5183385",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids = [\n",
    "    1590,   # Adult\n",
    "    1510,   # Breast Cancer Wisconsin (Diagnostic)\n",
    "    1461,   # Bank Marketing\n",
    "    24,     # Mushroom\n",
    "    40945   # Titanic\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd1b031-bc09-450d-a918-298a0d393e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_prepare(openml_id):\n",
    "    global y\n",
    "    global X\n",
    "    dataset = openml.datasets.get_dataset(openml_id)\n",
    "    print(f\">>> {dataset.name} (ID: {openml_id})\")\n",
    "    X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format='dataframe')\n",
    "    for col in X.select_dtypes(include=['category', 'object']):\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_imputed = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X.columns)\n",
    "    if y.dtype == 'category':\n",
    "        y = LabelEncoder().fit_transform(y)\n",
    "    zbior = X_imputed['Target'] = y\n",
    "    return X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef5f027-da27-436c-a0e2-2871ea57a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "zbior = fetch_and_prepare(1590)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e78d8-0df1-4316-a011-23838adb361f",
   "metadata": {},
   "source": [
    "# Optymalizacja hiperparametrów - zbiór Adult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79396f00-05af-4121-a0c4-30ad2d67eba0",
   "metadata": {},
   "source": [
    "## Regresja logistyczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f1b0b-ea6e-4a56-9eb8-9a240fd76d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(zbior.iloc[:, :-1], zbior['Target'], test_size=0.30, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    solver = trial.suggest_categorical('solver',['lbfgs','newton-cg','newton-cholesky','sag','saga'])\n",
    "    penalty,l1_ratio = None,None\n",
    "\n",
    "    if solver == 'lbfgs' or solver == 'newton-cg' or solver == 'newton-cholesky' or solver == 'sag':\n",
    "        penalty = trial.suggest_categorical('penalty', ['l2'])\n",
    "    elif solver == 'saga':\n",
    "        penalty = trial.suggest_categorical('penalty_saga', ['l1', 'l2', 'elasticnet'])\n",
    "        if penalty == 'elasticnet':\n",
    "            l1_ratio = trial.suggest_float('l1_ratio', 1e-5, 1.0)\n",
    "         \n",
    "    C = trial.suggest_float('C', 1e-4, 1e4, log=True)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    wyniki = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        X_train_fold = X_train_fold.reset_index(drop=True)\n",
    "        X_test_fold = X_test_fold.reset_index(drop=True)\n",
    "        y_train_fold = y_train_fold.reset_index(drop=True)\n",
    "        y_test_fold = y_test_fold.reset_index(drop=True)\n",
    "\n",
    "        X_train_fold = list(zip(*[X_train_fold[col] for col in X_train_fold]))\n",
    "        X_test_fold = list(zip(*[X_test_fold[col] for col in X_test_fold]))\n",
    "\n",
    "        regresja_logistyczna = LogisticRegression(penalty = penalty, C=C, solver=solver, l1_ratio=l1_ratio, max_iter=10000, random_state=42,\n",
    "                                                  ).fit(X_train_fold, y_train_fold)\n",
    "        regresja_logistyczna.predict(X_test_fold)\n",
    "\n",
    "        wynik = regresja_logistyczna.score(X_test_fold, y_test_fold)\n",
    "        wyniki.append(wynik)\n",
    "\n",
    "    rezultat = np.mean(wyniki)\n",
    "    return rezultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9e285-ea83-4c0f-a008-0a282bbd6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize',sampler=TPESampler())\n",
    "wynik = study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c27ec7-d24b-444d-8fa0-780a0198acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac81d9-eee7-4ef9-ae14-7902962f8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "regresja_logistyczna = LogisticRegression(penalty = 'elasticnet', C=0.3803420691574056, solver='saga', l1_ratio=0.9175083483232548, max_iter=5000, random_state=42,\n",
    "                                                  ).fit(X_train, y_train)\n",
    "regresja_logistyczna.predict(X_test)\n",
    "wynik = regresja_logistyczna.score(X_test, y_test)\n",
    "print(wynik)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2fdb37-8568-4fc2-8f53-c89bd280bb8b",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ce742-ef2b-4678-9c09-c4b9a9f43d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(zbior.iloc[:, :-1], zbior['Target'], test_size=0.30, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000, step=100)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 32, log=True)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10) \n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    wyniki = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        X_train_fold = X_train_fold.reset_index(drop=True)\n",
    "        X_test_fold = X_test_fold.reset_index(drop=True)\n",
    "        y_train_fold = y_train_fold.reset_index(drop=True)\n",
    "        y_test_fold = y_test_fold.reset_index(drop=True)\n",
    "\n",
    "        X_train_fold = list(zip(*[X_train_fold[col] for col in X_train_fold]))\n",
    "        X_test_fold = list(zip(*[X_test_fold[col] for col in X_test_fold]))\n",
    "\n",
    "        Las_losowy = RandomForestClassifier(n_estimators = n_estimators, max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                                            min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "        Las_losowy.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        Las_losowy.predict(X_test_fold)\n",
    "                                            \n",
    "        wynik = Las_losowy.score(X_test_fold, y_test_fold)\n",
    "        wyniki.append(wynik)\n",
    "\n",
    "    rezultat = np.mean(wyniki)\n",
    "    return rezultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e8ef13-0030-4d65-9faa-b9b761211d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize',sampler=TPESampler())\n",
    "wynik = study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953f94a-d939-4451-b9b3-a72c10f3ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54137ae1-7288-4b63-b82d-321b9fb29760",
   "metadata": {},
   "outputs": [],
   "source": [
    "Las_losowy = RandomForestClassifier(n_estimators = 1000, max_depth=18, min_samples_split=7,\n",
    "                                            min_samples_leaf = 1).fit(X_train,y_train)\n",
    "Las_losowy.predict(X_test)\n",
    "wynik = Las_losowy.score(X_test, y_test)\n",
    "print(wynik)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce797586-eb30-4264-b7d2-52cd5abe523b",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cc19cf-848e-4531-8bcb-4a98b7ff535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(zbior.iloc[:, :-1], zbior['Target'], test_size=0.30, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.6, 1.0)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 1, 10)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    wyniki = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        X_train_fold = X_train_fold.reset_index(drop=True)\n",
    "        X_test_fold = X_test_fold.reset_index(drop=True)\n",
    "        y_train_fold = y_train_fold.reset_index(drop=True)\n",
    "        y_test_fold = y_test_fold.reset_index(drop=True)\n",
    "\n",
    "        X_train_fold = list(zip(*[X_train_fold[col] for col in X_train_fold]))\n",
    "        X_test_fold = list(zip(*[X_test_fold[col] for col in X_test_fold]))\n",
    "\n",
    "        XGBoost = XGBClassifier(max_depth = max_depth, learning_rate = learning_rate, n_estimators = n_estimators,\n",
    "                               subsample = subsample, colsample_bytree = colsample_bytree, min_child_weight = min_child_weight)\n",
    "\n",
    "        XGBoost.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        XGBoost.predict(X_test_fold)\n",
    "                                            \n",
    "        wynik = XGBoost.score(X_test_fold, y_test_fold)\n",
    "        wyniki.append(wynik)\n",
    "\n",
    "    rezultat = np.mean(wyniki)\n",
    "    return rezultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a553fd1-9f7e-450b-b967-e40fa32acc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize',sampler=TPESampler())\n",
    "wynik = study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3bda8-dea9-474e-b7d1-bdce581a9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb172f-a66e-48ea-b69b-9208f56a5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost = XGBClassifier(max_depth = 7, learning_rate = 0.014059646736310738, n_estimators = 811,\n",
    "                               subsample = 0.8746931123404836, colsample_bytree = 0.7067553318391634, min_child_weight = 1).fit(X_train,y_train)\n",
    "XGBoost.predict(X_test)\n",
    "wynik = XGBoost.score(X_test, y_test)\n",
    "print(wynik)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
